{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madap/Documents/Coding/whisperExperiments/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values \n",
    "\n",
    "load_dotenv() \n",
    "\n",
    "hfToken = os.getenv(\"hftoken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_model = whisper.load_model(\"base\")\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\",\n",
    "                                    use_auth_token=hfToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization_result = pipeline(\"audioFiles/suchir1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = whisper_model.transcribe(\"audioFiles/suchir1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30s - 1.03s SPEAKER_01:  I wish they were\n",
      "1.03s - 1.48s SPEAKER_00: \n",
      "2.17s - 5.16s SPEAKER_01:  are screwed and sounded me\n",
      "5.92s - 9.35s SPEAKER_00:  你去 angry 你去杀我 你去 People\n",
      "10.27s - 11.57s SPEAKER_01: \n",
      "11.98s - 13.50s SPEAKER_01:  ......\n",
      "14.29s - 17.72s SPEAKER_00:  We will never change our soul apart.\n",
      "18.49s - 22.14s SPEAKER_01:  Oh, shit, we have to have... Oh, shit, we have to have...\n",
      "22.53s - 23.98s SPEAKER_00:  I shudshot him.\n"
     ]
    }
   ],
   "source": [
    "audio = Audio()\n",
    "audio_file = \"audioFiles/suchir1.wav\"\n",
    "\n",
    "for segment, _, speaker in diarization_result.itertracks(yield_label=True):\n",
    "    waveform, sample_rate = audio.crop(audio_file, segment)\n",
    "    text = whisper_model.transcribe(waveform.squeeze().numpy())[\"text\"]\n",
    "    print(f\"{segment.start:.2f}s - {segment.end:.2f}s {speaker}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Hey, what's up? What are you doing? Not much. Just playing some Minecraft. How about you? I'm trying to test out this audio detection program. That's really cool. What would the detection do? It will identify various speakers inside of an audio file. Oh, so will it detect me as a person and you as a person? Exactly. That's the goal.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhisperX Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
